{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9955825c-5163-4581-b4a1-76ff210e39a0",
   "metadata": {},
   "source": [
    "# Prospecção de Dados (Data Mining) DI/FCUL - TP01\n",
    "\n",
    "\n",
    "## Processing large quantities of data - an exposition for text procesing\n",
    "\n",
    "#### A simple tutorial by Andre Falcao (MC/DI/FCUL - 2023 - 202)\n",
    "\n",
    "This tutorial will try to solve a very simple problem: **from a set of documents, can we identify the ones that are more similar to each other?**\n",
    "\n",
    "The first part of this tutorial will focus on [18 of La Fontaine fables](https://en.wikipedia.org/wiki/La_Fontaine%27s_Fables), translated into English by William Trowbridge and made available to the public by [Project Gutenberg](https://www.gutenberg.org/ebooks/24108). The Text file was editted removing headers and copyright information as they would add noise to the data set. Each fable is then one document and the basic question stands: What documents are more similar to others\n",
    "\n",
    "First let's open our data set and print it out, as it is rather small (and actually entertaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9d417-c669-440d-961e-b96ef29dddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories=open(\"lafontaine.txt\", \"rt\").readlines()\n",
    "\n",
    "all_word_counts=[]\n",
    "texts=[]\n",
    "for i,story in enumerate(stories):\n",
    "    print(\"Story %d:\\n %s\" % (i, story))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785532de-42d2-4689-8195-752c58127eb0",
   "metadata": {},
   "source": [
    "Text  retrieved from the web many times contains weird characters that do not add content and end up bycreating artificial differences, so we will use the following 3 utilitary functions\n",
    "\n",
    "* The simplest possible `tokenizer` (this will eventually be replaced in the future with a more robust solution)\n",
    "* `remove_accents()` - this will remove all accents from a unicode text replacing it with the equivalent nonaccented words\n",
    "* `remove_stuff()` - will remove many weird and strange characters that occasionally appear in text scraped from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524fad2-e6d7-4ab8-9067-efeee60e52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def basic_word_tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "def remove_accents(s):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', s)\n",
    "    return u\"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "\n",
    "def remove_stuff(s):\n",
    "    for c in \"\\\\\\t0123456789Ææœ—‘’\\ufeff{|}“”.,()$£%&[]?@#!=;*+–\\\"ǁ\":\n",
    "        s=s.replace(c, \"\")\n",
    "    s=s.replace(\"-\", \" \")\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d18dcb2-b301-4427-a60a-0d1c466d8696",
   "metadata": {},
   "source": [
    "We will now add another function, that will use all these utilities, for extracting all the words form a set of documents (a corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7680feee-43dc-4a89-b1fb-81eb75303ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_words_from_corpus(corpus):\n",
    "    words_texts=[]\n",
    "    for i,text in enumerate(corpus):\n",
    "        text=text.strip().lower()\n",
    "        text=remove_accents(text)\n",
    "        text=remove_stuff(text)\n",
    "        text=text.lower()\n",
    "        words = basic_word_tokenizer(text)\n",
    "        words_texts.append(words)\n",
    "    return words_texts\n",
    "\n",
    "\n",
    "words_texts = get_words_from_corpus(stories)\n",
    "\n",
    "#let's print out the first 20 words of the first five stories\n",
    "for i, words in enumerate(words_texts[:5]):\n",
    "    print(\"Story %d:\\n %s\" %(i, words[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f133fbb2-d6d0-430a-9dd7-8148102a4f99",
   "metadata": {},
   "source": [
    "Other things we will eventually need is to have the unique words of each document and also  the set of all the unique words in a given corpus\n",
    "\n",
    "We will accomplish both objectives with Python sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdac11dd-fed7-4059-bb09-d60c5edf603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_all_words(words_text_sets):\n",
    "    all_words=set()\n",
    "    for words in words_text_sets: all_words |= words\n",
    "    return all_words\n",
    "\n",
    "words_text_sets = [set(words) for words in words_texts]\n",
    "all_words=calc_all_words(words_text_sets)\n",
    "for i, word in enumerate(list(all_words)[:20]):\n",
    "    print(\"Word %d: %s\" %(i, word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78571a44-aabe-41e1-9c74-44954b7c67d4",
   "metadata": {},
   "source": [
    "### Question: What are the stories that are most similar in content?\n",
    "\n",
    "### Solution 1:  we might compare by checking how many words each story shares and make a table\n",
    "\n",
    "We could do this by making sets of the existing words in each text, which will take out all repetitions and then make comparisons among all sets. A very common way of doing that would be to compute the Cosine Similarity that checks the ratio of the scores of the common words of a document \n",
    "\n",
    "$$CosSim=\\dfrac{\\sum_i{A_i.B_i}}{\\sqrt{\\sum_i{A_i^2}}.\\sqrt{\\sum_i{B_i^2}}}$$\n",
    "\n",
    "\n",
    "for a simple approach  A_i and B_i correspond to the presence of word $i$ in Document $A$ or document $B$\n",
    "\n",
    "Another way to make comparisons would be to use the jaccard score that could be easily computed with python sets as it is just the ratio of the intersection with the union of both sets\n",
    "\n",
    "$$Jaccard=\\dfrac{T_a \\cap T_b}{T_a \\cup T_b}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa8baa-f552-470b-b4f4-280eda46b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_text_sets=[set(words) for words in words_texts]\n",
    "from math import sqrt\n",
    "def cos_similarities(word_sets):\n",
    "    sims=[]\n",
    "    for a in range(len(word_sets)-1):\n",
    "        for b in range(a+1, len(word_sets)):\n",
    "            CosSim=len(word_sets[a] & word_sets[b]) / (sqrt(len(word_sets[a])*len(word_sets[b])))\n",
    "            sims.append((CosSim, (a,b)))\n",
    "    return sims\n",
    "\n",
    "\n",
    "sims = cos_similarities(words_text_sets)\n",
    "\n",
    "#now let's sort the list in descending order so that the most similar stories will appear\n",
    "sims = sorted(sims, reverse=True)\n",
    "\n",
    "#now let's get the 5 most common text pairs\n",
    "for J, text_pair in sims[:5]: \n",
    "    print( \"%s has similarity: %7.4f\" % (text_pair, J))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1984eb9f-007e-4b03-9bd0-4093ee132850",
   "metadata": {},
   "source": [
    "This function willl be critical in assessing the similarity of many pairs of documents thus it will be critical to assess its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea614d-5620-4b74-8211-e6dbad32551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sims = cos_similarities(words_text_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597cdd79-76fa-4b7e-8fa8-3968a2d12900",
   "metadata": {},
   "source": [
    "#### Exercises: \n",
    "1. Modify the text_similarity so that it will use the Jaccard score \n",
    "2. Compare the results and discuss them\n",
    "3. Check its performance and comment the differences\n",
    "4. [to do at home!] can the above function be sped up if instead of using strings for words we use integers as indices for each individual word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f6e6d-e5df-4823-a6f2-85fff7e609ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!! solution 1 !!!!!!!!!\n",
    "def jacc_similarities(word_sets):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78465ad-7953-4b81-ad37-f2b24d04fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sims = jacc_similarities(words_text_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f3b55d-dc54-4b4b-a26c-243efec182c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!! solution of exercise 4 !!!!!!!!!\n",
    "\n",
    "# first let's index each word\n",
    "\n",
    "#finally, let's (re)construct the stories with the word indexes:\n",
    "\n",
    "# now with our stories properly word indexed we can recompute the \n",
    "\n",
    "# similarities which shuld be the same and we will print out  the 5 similar stories\n",
    "\n",
    "    \n",
    "#Let's verify the computing time\n",
    "%timeit sims = cos_similarities(idxs_text_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be61e62-7bb8-4ca1-894a-521258f09517",
   "metadata": {},
   "source": [
    "## A different solution\n",
    "\n",
    "The solution above is ok but we are not actually entering into  our computation the following issues:\n",
    "1. **Words have different importances**. The word \"the\" or \"a\" very much common words have different importance than \"eagle\", \"running\" or \"manners\"\n",
    "2. **We are disregarding the amount of times a word appear on a text**. A word more common should count more then a word that appears only once\n",
    "\n",
    "\n",
    "### Introducing TF.IDF - A way off the quagmire\n",
    "\n",
    "TFIDF is a calculation that allows to assign values to each word in our corpus and it is a product of 2 values \n",
    "\n",
    "$$ TFIDF_{ij} = TF_{ij}.IDF_i $$\n",
    "\n",
    "### Defining TF\n",
    "\n",
    "first let's define TF. which solves our Problem 2. How to emphasize the importance that each word has in a text? This score is defined as\n",
    "\n",
    "$$ TF_{ij} = \\dfrac{C_{ij}}{max_k(C_{kj})} $$\n",
    "\n",
    "where $C_{ij}$ is the number of times term $i$ appears on document $j$. So we will need a `word counter` that should be able to count the number of occurrences of each word on each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f41d6-5157-4b34-83e7-e85cb4111eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(words):\n",
    "    #1. get uniques\n",
    "    unique_words=set(words)\n",
    "    #2. make a dictionary for counting\n",
    "    D=dict(zip(unique_words, [0]*len(unique_words)))\n",
    "    #3. count all\n",
    "    for w in words: D[w]+=1\n",
    "    return D  \n",
    "\n",
    "def TF(word_counts):\n",
    "    #get the counts\n",
    "    counts  = word_counts.values()\n",
    "    if len(counts)==0: return {}\n",
    "    the_max = max(counts)   #compute the maximum\n",
    "    #return a dictionary that for each word returns the ratio of wc/max_wc\n",
    "    return dict(zip(word_counts.keys(), [c/the_max for c in counts]))    \n",
    "\n",
    "#let's try the above functions for story one\n",
    "text=words_texts[0]\n",
    "wcounts =word_counter(text)\n",
    "tfs = TF(wcounts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3974c017-80a1-4422-a18d-e79d9b269794",
   "metadata": {},
   "source": [
    "and let's look at the TFs for the first 10 words of this little story:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115aed79-dbb6-4b94-932d-73cc1adb4cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in text[:10]:\n",
    "    print(\"%12s - Counts:%3d; TF: %7.4f\" % (word, wcounts[word], tfs[word]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cc049d-b5d3-4d97-bff0-0c0aa21c6713",
   "metadata": {},
   "source": [
    "Notice that the TFs correspond to one text only so we have to compute the TFs for all documents in a new function\n",
    "\n",
    "The function will return the TFs for each document in a array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d623943-cc94-487e-8d6c-bcb281e5d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tfs(words_texts):\n",
    "    all_tfs=[]\n",
    "    for words in words_texts:\n",
    "        wcounts = word_counter(words)\n",
    "        all_tfs.append(TF(wcounts))\n",
    "    return all_tfs\n",
    "\n",
    "all_tfs = calc_tfs(words_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4102c0-cc53-4756-bb2d-aa768a88462c",
   "metadata": {},
   "source": [
    "#### Defining IDF\n",
    "\n",
    "IDF aims at solving problem 1. Not all words are equal, and some have more meaning than others. Words that appear in all documents of a corpus should not be that interesting, while some words quite rare should be scored more heavily.  \n",
    "\n",
    "$$ IDF_i = log_2{\\dfrac{N}{n_i}} $$\n",
    "\n",
    "Where N is the total number of words in a corpus and $n_i$ is the number of documents in which the word $i$ appears in. This requires us to have a complete list of the words. The IDF will assign a global score to each word. The more uncommon it is, the higher the score. Words that appear always, like \"the\" or \"a\" will have score of zero, or very close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ae319-3797-4ffd-8554-715a5b01a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "def IDF(all_words, doc_word_counts):\n",
    "    #first initialize a new dictionary with one entry for each word\n",
    "    D=dict(zip(all_words, [0]*len(all_words)))\n",
    "    N=len(doc_word_counts)\n",
    "    for doc in doc_word_counts:\n",
    "        for word in doc: D[word]+=1\n",
    "    return {w: log2(N/D[w]) for w in D}\n",
    "\n",
    "idfs = IDF(all_words, words_text_sets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaaa414-e650-4159-a501-54125782a8d0",
   "metadata": {},
   "source": [
    "With the global IDFs computed we can now show the results of the first 10 words of the first fable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9a54f-6e99-4763-bd17-ea4523eed330",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=words_texts[0]\n",
    "wcounts =word_counter(text)\n",
    "tfs=TF(wcounts)\n",
    "\n",
    "for word in text[:10]:\n",
    "    print(\"%12s - Counts:%3d; TF: %7.4f IDF: %7.4f -> TFIDF: %7.4f\" % (word, wcounts[word], \n",
    "                                                                       tfs[word], idfs[word],\n",
    "                                                                       tfs[word]*idfs[word]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fb7fd1-6fce-42d2-9c02-4c6971f81a7e",
   "metadata": {},
   "source": [
    "### Computing document similarity with TFIDF\n",
    "\n",
    "We will now make a little function that receives the indexes of the documents, the unique words of both documents, and the TFs and IDFs previously computed and will produce the cosine distance for each pair of documents\n",
    "\n",
    "We are going to use numpy for its broadcasting capabilities that will speed up the calculations of the similarities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a4b81-e895-48a5-8a70-2853f47b825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cosine_similarity_tfidf(idx1, idx2, words_text_sets, all_tfs, idfs):\n",
    "    text1= words_text_sets[idx1]\n",
    "    text2= words_text_sets[idx2]\n",
    "    tfs1=all_tfs[idx1]\n",
    "    tfs2=all_tfs[idx2]\n",
    "\n",
    "    common_words = text1 & text2\n",
    "    if len(common_words)==0: return 0.0\n",
    "    common_tfidfs = [tfs1[w]*tfs2[w]*idfs[w]*idfs[w] for w in common_words]\n",
    "\n",
    "    #squared tfidfs\n",
    "    tfidfs2_1=np.array([tfs1[w]*idfs[w] for w in text1])**2\n",
    "    tfidfs2_2=np.array([tfs2[w]*idfs[w] for w in text2])**2\n",
    "\n",
    "    return sum(common_tfidfs)/(np.sqrt(tfidfs2_1.sum())*np.sqrt(tfidfs2_2.sum()))\n",
    "\n",
    "dst=cosine_similarity_tfidf(1, 3, words_text_sets, all_tfs, idfs)\n",
    "print(\"The distance between stories 1 and 3 is %7.4f\" % ( dst)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0273110e-2bf3-40a8-9962-03a638b674f4",
   "metadata": {},
   "source": [
    "we can now compute all distances between all pairs of documents and find the most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08114ee8-c9bc-470a-ad0d-64cea32ed1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_similarities2(words_text_sets, all_tfs, idfs):\n",
    "    N=len(words_text_sets)\n",
    "    sims=[]\n",
    "    for i in range(N-1):\n",
    "        for j in range(i+1, N):\n",
    "            sim = cosine_similarity_tfidf(i,j, words_text_sets, all_tfs, idfs)\n",
    "            sims.append((sim, (i,j)))\n",
    "    return sims\n",
    "\n",
    "sims = text_similarities2(words_text_sets, all_tfs, idfs)\n",
    "\n",
    "sims = sorted(sims, reverse=True)\n",
    "for J, text_pair in sims[:5]: \n",
    "    print( \"%s has similarity: %7.4f\" % (text_pair, J))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379b1c75-1dfb-4509-90fb-79ef1c044137",
   "metadata": {},
   "source": [
    "This is all very nice, but what is the performance impact of this new similarity metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011c55c-aa87-48a0-87fa-7a29a272308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sims = text_similarities2(words_text_sets, all_tfs, idfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653099a8-dc61-4cde-98f8-042a0521215a",
   "metadata": {},
   "source": [
    "#### Exercises: \n",
    "1. What are the common words between documents 6 and 16, and justify why they appear closer. \n",
    "2. analise and comment the results\n",
    "    1. Are all words equally impoertant?\n",
    "    2. What might improve the results?\n",
    "    3. What problems would this entail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e8999e-0e46-4ae2-a4ec-ed63372c0b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !!!! Solution to exercise 1 !!!!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85b87de-b7e8-42ff-87ad-b3dbc89d23da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Expanding this approach to a larger corpus\n",
    "\n",
    "We are going to use a very small sample from [the Wikipedia from Nov 2020](https://www.kaggle.com/datasets/ltcmdrdata/plain-text-wikipedia-202011) that is made available in Kaggle. The full dataset is about 24 GB of data, of which we are only using 40 MB in JSON file for a total of about 14,500 documents. [the quality of the entries is very variable with occasional hypertext markings in several entries]\n",
    "\n",
    "Python makes it easy to process these files by using the json standard library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c11e65-5d38-45ee-8c69-39478946a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = json.load(open('file1.json', \"rt\", encoding=\"utf-8\"))\n",
    "  \n",
    "print(\"Number of docs:\", len(data))\n",
    "print(\"Showing first 10 titles\")\n",
    "for d in data[:10]:\n",
    "    print(d[\"id\"],\"--->\", len(d[\"text\"]) , \"[\", d[\"title\"], \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863d035-a154-45bf-ae88-c4c6a4d2144e",
   "metadata": {},
   "source": [
    "First let's create a new corpus from this data and then make some text processing and identify all words and all unique words as before\n",
    "\n",
    "**Note:** this should take slightly longer as 14,500 documents are significantly more difficult to process than 18 short fables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b7c24-74f1-434a-bf5e-b76b6d4ad97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [d[\"text\"] for d in data]\n",
    "\n",
    "words_texts     = get_words_from_corpus(corpus)\n",
    "words_text_sets = [set(words) for words in words_texts]\n",
    "all_words       = calc_all_words(words_text_sets)\n",
    "\n",
    "print(\"N. of texts:\", len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43431a1e-c016-447d-b711-6b08f317cb4a",
   "metadata": {},
   "source": [
    "As before let's compute the TF and IDFs for all documents and words in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c6a6c-4dc9-4008-a061-cb0952478fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = IDF(all_words, words_text_sets)\n",
    "all_tfs=calc_tfs(words_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9267d9-55b5-45d2-bc6a-11b3c861b175",
   "metadata": {},
   "source": [
    "### Time for a break\n",
    "\n",
    "Before we continue let's examine what's ahead: We need to compute the distances of all documents to all documents and **this is a quadratic time operation $O(N^2)$**\n",
    "\n",
    "The number of computations should be:\n",
    "\n",
    "$$nc= \\dfrac{N.(N-1)}{2}$$\n",
    "\n",
    "so for 14,679 documents it should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8319874c-bae2-4cad-a102-d75eb3d5e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(corpus)\n",
    "print(N*(N-1)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c44420-fdb3-4865-acf4-6f7876258ad7",
   "metadata": {},
   "source": [
    "Assuming we have sufficient memory to accomodate these results, how long will it take for processing it?\n",
    "\n",
    "Let's start with 20 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f26373-47bc-4732-88b2-47aaebbf895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = text_similarities2(words_text_sets[:20], all_tfs, idfs)\n",
    "\n",
    "sims = sorted(sims, reverse=True)\n",
    "for J, text_pair in sims[:5]: \n",
    "    print( \"%s has similarity: %7.4f\" % (text_pair, J))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61beb548-cf70-43c7-aeb2-ebe7d2dbdd10",
   "metadata": {},
   "source": [
    "Let's check documents 6 and 13 as they look really similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae4da9-5f7e-470c-bf11-d64c99f9635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus[6])\n",
    "print()\n",
    "print(corpus[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ec39fb-de41-494b-a202-f7cb88306e27",
   "metadata": {},
   "source": [
    "Also let's time this using python's common `time()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73df006a-1916-43ef-bf08-8e2f96ac0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "time1=time()\n",
    "sims = text_similarities2(words_text_sets[:20], all_tfs, idfs)\n",
    "time2=time()\n",
    "print(\"the operation took %8.6f seconds\" % (time2-time1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f25fe26-0379-490f-b11d-a0dd17c0c2df",
   "metadata": {},
   "source": [
    "#### Solved Exercises\n",
    "\n",
    "1. increase the number of documents to search similarities from up to 500 documents\n",
    "2. plot the number of documents vs execution time (use matplotlib!)\n",
    "3. Comment your results\n",
    "4. Estimate how much would it take for processing the full corpus (~14500 documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fcdb46-95ed-482c-841d-f4ec3714fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndocs=range(50, 501, 50)\n",
    "times=[]\n",
    "for n in ndocs:\n",
    "    t1=time()\n",
    "    sims = text_similarities2(words_text_sets[:n], all_tfs, idfs)\n",
    "    t2=time()\n",
    "    print(\"%3d --> %8.4f seconds\" % (n, t2-t1)) \n",
    "    times.append(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb4eef0-e17a-480f-8dcb-742cdb705347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "times=np.array(times)\n",
    "\n",
    "plt.plot(ndocs, times)\n",
    "plt.title(\"NDocs vs Time\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62f79e4-4236-40ec-abc3-d601616ba2b3",
   "metadata": {},
   "source": [
    "This could perhaps be better visualised if we transform the times into its square root, where its linear dimension should become apparent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d0bc5-cc19-4aff-b20c-b3cfe10874ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(ndocs, np.sqrt(times))\n",
    "plt.title(\"NDocs vs sqrt(Time)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf2851a-7957-4dfd-a680-438031f7e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!!!!! Solution of exercise 4!!!!!!!!!!!!!!!!\n",
    "# compute slope\n",
    "slope=(np.sqrt(times)[-1]-np.sqrt(times)[1])/(ndocs[-1]-ndocs[1])\n",
    "print(\"To compute the entire corpus it would take %6.3f hours\" % ((slope*len(corpus))**2/3600))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b185aed-bfdc-44b9-b8cc-44944765b822",
   "metadata": {},
   "source": [
    "## Entering ray - Easy distributed processing for Python\n",
    "\n",
    "[Ray](https://www.ray.io/) is a very powerful library for distributed computing that allows load distribution between different logical units on the same machine, using GPUs, and different servers. Setting up a ray cluster is very easy and the same exact procedures used for distributing heavy computing loads in a machine, are the same if you have a data cluster or working in a cloud computing environment\n",
    "\n",
    "ray is not installed by default so it must be installed on the command line with `pip install ray` or, if you feel lucky, you may tray the line below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784cc60d-7116-4a2f-94fd-c3062274cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de68c937-a2d2-4990-b9c7-e8c24931ef12",
   "metadata": {},
   "source": [
    "Ray is alwys initialized with ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f5efa-6d94-42f9-a3b1-39ce062479dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d213b-96f3-4089-bc85-1163d8b44aad",
   "metadata": {},
   "source": [
    "as a very simple example on how ray works let's create a dummy function that just wastes time (like a normal function would do). This function just uses the sleep function for sitting idle and the time (in seconds) it takes is a parameter and returns a simple string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b301c2a7-dd1d-4b4c-a3b0-8efaf4b347ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def dummy(sleep):\n",
    "    time.sleep(sleep)\n",
    "    return f\"Sleep time {sleep}\"\n",
    "\n",
    "sleep_times = [1.5, 0.1, 0.2, 0.1, 0.5, 0.7, 0.5, 0.4, 1.5, 1.3, 0.7, 0.6, 0.3, 0.8]\n",
    "\n",
    "t1=time.time()\n",
    "results=[dummy(st) for st in sleep_times]\n",
    "t2=time.time()\n",
    "\n",
    "print(\"The time spent was:\", t2-t1)\n",
    "print(\"The time expected of sleep would be:\", sum(sleep_times))\n",
    "for res in results: print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fa09da-568e-4d11-b46d-04b992a0ab7e",
   "metadata": {},
   "source": [
    "now we can parallelize this with ray by decorating the function as a remote function (with `@ray.remote`), so ray will make use of resources avaliable to assign each task to each logical unit. and if there are more tasks than processing units, ray will manage the process and as soon as a new resource becomes available, it will be assigned.\n",
    "\n",
    "The results from a remote function may have not been completed, they are a `future`, which means a promise that the result will become ready soon. to actually get the result we have use the method `ray.get()`\n",
    "\n",
    "So to parallelize our dummy problem we will rewrite our code like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262dc89-8d65-49f7-8abc-6954d751c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def dummy(sleep):\n",
    "    time.sleep(sleep)\n",
    "    return f\"Sleep time {sleep}\"\n",
    "\n",
    "\n",
    "t1=time.time()\n",
    "res_futures=[dummy.remote(st) for st in sleep_times]\n",
    "t2=time.time()\n",
    "results = ray.get(res_futures) \n",
    "t3=time.time()\n",
    "print(\"The time spent for dispatching the tasks:\", t2-t1)\n",
    "print(\"The time spent for getting the results:\", t3-t2)\n",
    "print(\"The total time spent:\", t3-t1)\n",
    "print(\"The order of the results is:\")\n",
    "for res in results: print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccd8658-2c25-48a9-a7d2-263be404b7c0",
   "metadata": {},
   "source": [
    "## A local Alternative to Ray - Using Python's multiprocessing \n",
    "\n",
    "the `multiprocessing` library allows for fast local processing taking advantage of many cores a machine may have, whithout the overload of ray for handling  much more complex situations \n",
    "\n",
    "The Multiprocessing module works by creating a pool of processes that can be run asynchronously and we access these resources by mapping each data item to each process. As such we will use an actual `map` function, that takes two arguments: a function and a list containing the data to be processed\n",
    "\n",
    "Here is a simple example with the `dummy` sleep function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca03e10-5502-4440-9db2-141945b7f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep, time\n",
    "\n",
    "def dummy(sleep_time):\n",
    "    print(\"starting to sleep for:\", sleep_time)\n",
    "    sleep(sleep_time)\n",
    "    return f\"Sleep time {sleep_time}\"\n",
    "\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "\n",
    "sleep_times = [1.5, 0.1, 0.2, 0.1, 0.5, 0.7, 0.5, 0.4, 1.5, 1.3, 0.7, 0.6, 0.3, 0.8]\n",
    "t1=time()\n",
    "with Pool(5) as p:\n",
    "    res = p.map(dummy, sleep_times)\n",
    "t2=time()\n",
    "print(\"The time spent for finishing:\", t2-t1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f245e017-0260-426b-9c0c-310cb74258f6",
   "metadata": {},
   "source": [
    "Now to apply this resource to our problem we need to define our problem as a mapping problem, taking note that the map only accepts one argument and our similarity function actually requires 4 arguments (the row to process, the full set of words, the tfs and idfs for all words)\n",
    "\n",
    "Two alternatives would be possible:\n",
    "* Use global variables - which would eventually be solved by the multiprocessing environment creating local copies\n",
    "* Redefine our list of arguments, where each element is tuple constituted of all the required data which is later unpacked by the distributed function\n",
    "\n",
    "We will follow the second approach which can be trivially implemented by slightly rewriting the involved functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b96645-54d8-4faf-aa26-3b5ce19928ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cos_sim_mp(args):\n",
    "    text1, text2, tfs1, tfs2, idx1, idx2, idfs = args\n",
    "    common_words = text1 & text2\n",
    "    if len(common_words)==0: return 0.0, (idx1, idx2)\n",
    "    common_tfidfs = [tfs1[w]*tfs2[w]*idfs[w]*idfs[w] for w in common_words]\n",
    "\n",
    "    #squared tfidfs\n",
    "    tfidfs2_1=np.array([tfs1[w]*idfs[w] for w in text1])**2\n",
    "    tfidfs2_2=np.array([tfs2[w]*idfs[w] for w in text2])**2\n",
    "\n",
    "    return sum(common_tfidfs)/(np.sqrt(tfidfs2_1.sum())*np.sqrt(tfidfs2_2.sum())), (idx1, idx2)\n",
    "\n",
    "\n",
    "def text_similarities_mp(words_text_sets, all_tfs, idfs):\n",
    "    N = len(words_text_sets)\n",
    "    #here we define the new arguments\n",
    "    \n",
    "    args=[(words_text_sets[i], \n",
    "           words_text_sets[j],\n",
    "           all_tfs[i], \n",
    "           all_tfs[j], i,j, idfs) for i in range(N-1) for j in range(i+1, N)]\n",
    "    with Pool(None) as p:\n",
    "        sims=p.map(cos_sim_mp, args)\n",
    "    \n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12f4c6-e56b-49be-a5be-7474fc7f9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sims = text_similarities_mp(words_text_sets[:20], all_tfs, idfs)\n",
    "sims = sorted(sims, reverse=True)\n",
    "for J, text_pair in sims[:5]: \n",
    "    print( \"%s has similarity: %7.4f\" % (text_pair, J))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bba3977-b72b-4b4e-80b4-77787194e537",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Exercises\n",
    "1. Measure and plot the performance of this approach by testing 10, 20,...,100 documents and compare it to the other approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117fdca0-bd10-4347-b79a-ffa579059591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HERE try it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c085d7e-7a54-4d42-82c4-3d66fea1edaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c611daf9-24e2-44c6-b350-2bfa6220cc64",
   "metadata": {},
   "source": [
    "### Using Distributed processing with Ray for speeding up similarity calculations\n",
    "\n",
    "**WARNING** The code below, for some Ray installations, may be **EXTREMELY SLOW!**  - It is outside the scope of this course to guarantee a common, fast and reliable Ray installation\n",
    "\n",
    "We will rewrite slightly our cosine similarity so that it may be easier to process and integrate with our previous code. The only thing is that this function will ruturn not only the similarity but a tuple of the indexes of the two documents involved. This function is not going to be declared remote.\n",
    "\n",
    "What will be declared remote is a new function that will encompass the inside loop of the `text_similarities`, so that each core will receive one document as its basis and process its similarities to all the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9b115-c997-4be8-a5e0-da24dcf7ddf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@ray.remote\n",
    "def text_row_sims(i, words_text_sets, all_tfs, idfs):\n",
    "    N=len(words_text_sets)\n",
    "    sims=[]\n",
    "    for j in range(i+1, N):\n",
    "        res = cos_sim_ray(i, j, words_text_sets, all_tfs, idfs)\n",
    "        sims.append(res)\n",
    "    return sims\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a4e1a-ddd2-4652-a6f8-e5189195e2d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally the most important function, the base call that is going to distribute the load to all the workers. As before we will call the remote function for each base document\n",
    "\n",
    "Yet one further aspect must be referred to. Sending the `word text sets`, the `idfs` and the `tfs` to each worker (that amay not even be on the same machine, might be a very time consuming process, as these resources will be common to all the distributed processing. As such ray allows the creation of copies of those resources in a common shared spaced that can be accessed thorgh special references. These references are then used instead of the actual parameters to the remote function, that is then able to use them without actually being continuously receiving them. The only thing that the remote function receives is a reference that will allow the access to this resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cade9e8a-ec67-4e53-add7-4e23c51a2853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def text_similarities_ray(words_text_sets, all_tfs, idfs):\n",
    "    N=len(words_text_sets)\n",
    "    r_wts=ray.put(words_text_sets)\n",
    "    r_tfs=ray.put(all_tfs)\n",
    "    r_idfs=ray.put(idfs)\n",
    "    res=[]\n",
    "    for i in range(N-1):\n",
    "        res_futures=text_row_sims.remote(i, r_wts, r_tfs, r_idfs)\n",
    "        res.append(res_futures)\n",
    "    sims=ray.get(res)\n",
    "    return reduce(lambda a,b: a+b, sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca481f-0414-4beb-80d2-11fc92054c6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's confirm that the results are the same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd36bd7-9e6f-41bf-bfe3-128f992dfaa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sims=text_similarities_ray(words_text_sets[:20], all_tfs, idfs)\n",
    "sims = sorted(sims, reverse=True)\n",
    "for J, text_pair in sims[:5]: \n",
    "    print( \"%s has similarity: %7.4f\" % (text_pair, J))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb88e5-89f7-41b9-8b41-5581615ced92",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Exercises [if you can get a reasonably fast Ray installation]\n",
    "\n",
    "1. Measure the performance of this approach by testing 10, 20,...,100 documents\n",
    "2. Can you explain the performance differences?\n",
    "3. Plot the (ndocs, time) graph and comment the results\n",
    "4. in what situations would this approach be clearly better than the single processing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d6d9c-ef02-4647-89bd-be7975e94044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !!!!!! Solução problema 1 !!!!!!!!!!!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aef67d2-b586-4066-bdc1-a0c0c99ff83c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !!!!!! Solução problema 3 !!!!!!!!!!!!!!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
